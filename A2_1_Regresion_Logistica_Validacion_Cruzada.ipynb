{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd8dc5b",
   "metadata": {},
   "source": [
    "# A2.1 Regresión Logística y Validación Cruzada\n",
    "\n",
    "**Autor:** Ricardo Arath Sanchez Aguirre\n",
    "\n",
    "**Materia:** SC3314 – Inteligencia Artificial  \n",
    "**Universidad:** Universidad de Monterrey  \n",
    "**Profesor:** Dr. Antonio Martínez Torteya  \n",
    "\n",
    "---\n",
    "\n",
    "## Índice\n",
    "1. [Introducción](#1-introducción)\n",
    "2. [Fundamentos Teóricos](#2-fundamentos-teóricos)\n",
    "3. [Carga y Exploración de Datos](#3-carga-y-exploración-de-datos)\n",
    "4. [Preparación de Datos](#4-preparación-de-datos)\n",
    "5. [Implementación de Regresión Logística](#5-implementación-de-regresión-logística)\n",
    "6. [Validación Cruzada](#6-validación-cruzada)\n",
    "7. [Evaluación del Modelo](#7-evaluación-del-modelo)\n",
    "8. [Conclusiones](#8-conclusiones)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57293159",
   "metadata": {},
   "source": [
    "# 1. Introducción\n",
    "\n",
    "## 1.1 Contexto del Análisis\n",
    "\n",
    "En este análisis utilizamos la **Estadística de Matrimonios 2024** del INEGI para implementar un modelo de **Regresión Logística**, uno de los algoritmos fundamentales del aprendizaje supervisado para problemas de clasificación.\n",
    "\n",
    "## 1.2 Problema de Clasificación\n",
    "\n",
    "**Objetivo:** Predecir el **régimen matrimonial** (Sociedad Conyugal vs Separación de Bienes) basándose en las características sociodemográficas de los contrayentes.\n",
    "\n",
    "### ¿Por qué este problema?\n",
    "\n",
    "El régimen matrimonial es una decisión importante que refleja:\n",
    "- **Nivel socioeconómico**: Personas con mayor patrimonio tienden a elegir separación de bienes\n",
    "- **Edad de los contrayentes**: Segundas nupcias suelen preferir separación de bienes\n",
    "- **Nivel educativo**: Mayor educación puede asociarse con mayor conciencia legal\n",
    "- **Contexto geográfico**: Diferencias culturales entre regiones\n",
    "\n",
    "## 1.3 Variables de Interés\n",
    "\n",
    "| Variable | Tipo | Descripción |\n",
    "|----------|------|-------------|\n",
    "| **regimen_ma** (objetivo) | Binaria | 1=Sociedad Conyugal, 2=Separación de Bienes |\n",
    "| edad_con1, edad_con2 | Numérica | Edades de los contrayentes |\n",
    "| escol_con1, escol_con2 | Ordinal | Nivel de escolaridad |\n",
    "| tam_loc_re | Ordinal | Tamaño de localidad |\n",
    "| ent_regis | Categórica | Entidad federativa |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfae45a",
   "metadata": {},
   "source": [
    "# 2. Fundamentos Teóricos\n",
    "\n",
    "## 2.1 ¿Qué es la Regresión Logística?\n",
    "\n",
    "La **Regresión Logística** es un algoritmo de clasificación supervisada que modela la probabilidad de que una observación pertenezca a una clase particular.\n",
    "\n",
    "### Diferencias con Regresión Lineal\n",
    "\n",
    "| Aspecto | Regresión Lineal | Regresión Logística |\n",
    "|---------|------------------|--------------------|\n",
    "| **Variable objetivo** | Continua | Categórica (binaria) |\n",
    "| **Predicción** | Valor numérico | Probabilidad [0, 1] |\n",
    "| **Función** | $f(x) = wx + b$ | $f(x) = \\sigma(wx + b)$ |\n",
    "| **Función de costo** | MSE | Cross-Entropy (Log Loss) |\n",
    "\n",
    "## 2.2 La Función Sigmoide\n",
    "\n",
    "La **función sigmoide** (o logística) transforma cualquier valor real a un rango entre 0 y 1:\n",
    "\n",
    "$$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "Donde $z = \\mathbf{w} \\cdot \\mathbf{x} + b$ (combinación lineal de las características).\n",
    "\n",
    "### Propiedades de la función sigmoide:\n",
    "- **Rango**: $(0, 1)$ - ideal para representar probabilidades\n",
    "- **Punto medio**: $\\sigma(0) = 0.5$\n",
    "- **Asintótica**: Se aproxima a 0 cuando $z \\to -\\infty$ y a 1 cuando $z \\to +\\infty$\n",
    "- **Derivada**: $\\sigma'(z) = \\sigma(z)(1 - \\sigma(z))$ - facilita el cálculo del gradiente\n",
    "\n",
    "## 2.3 Función de Costo (Log Loss)\n",
    "\n",
    "La función de costo para regresión logística es la **entropía cruzada binaria** (Binary Cross-Entropy):\n",
    "\n",
    "$$J(\\mathbf{w}, b) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(\\hat{y}^{(i)}) + (1 - y^{(i)}) \\log(1 - \\hat{y}^{(i)}) \\right]$$\n",
    "\n",
    "Donde:\n",
    "- $m$ = número de muestras\n",
    "- $y^{(i)}$ = etiqueta real (0 o 1)\n",
    "- $\\hat{y}^{(i)} = \\sigma(\\mathbf{w} \\cdot \\mathbf{x}^{(i)} + b)$ = probabilidad predicha\n",
    "\n",
    "### ¿Por qué Log Loss y no MSE?\n",
    "- MSE en clasificación produce una superficie de costo **no convexa** con múltiples mínimos locales\n",
    "- Log Loss es **convexa**, garantizando un único mínimo global\n",
    "- Penaliza más fuertemente las predicciones muy seguras pero incorrectas\n",
    "\n",
    "## 2.4 Descenso del Gradiente\n",
    "\n",
    "Los parámetros se actualizan iterativamente:\n",
    "\n",
    "$$w_j := w_j - \\alpha \\frac{\\partial J}{\\partial w_j}$$\n",
    "\n",
    "$$b := b - \\alpha \\frac{\\partial J}{\\partial b}$$\n",
    "\n",
    "Donde:\n",
    "$$\\frac{\\partial J}{\\partial w_j} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)}) x_j^{(i)}$$\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)})$$\n",
    "\n",
    "## 2.5 Validación Cruzada (Cross-Validation)\n",
    "\n",
    "La **validación cruzada K-Fold** es una técnica para evaluar la capacidad de generalización del modelo:\n",
    "\n",
    "1. Divide los datos en K particiones (folds) de tamaño similar\n",
    "2. Para cada fold $k$:\n",
    "   - Usa fold $k$ como conjunto de validación\n",
    "   - Usa los otros $K-1$ folds como entrenamiento\n",
    "   - Evalúa el modelo en el fold de validación\n",
    "3. Promedia las métricas de los K experimentos\n",
    "\n",
    "### Ventajas de K-Fold:\n",
    "- Usa **todos los datos** para entrenamiento y validación\n",
    "- Proporciona una estimación más **robusta** del desempeño\n",
    "- Reduce la varianza en la estimación del error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f42b55c",
   "metadata": {},
   "source": [
    "# 3. Carga y Exploración de Datos\n",
    "\n",
    "## 3.1 Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6d938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Modelos y métricas de Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             confusion_matrix, classification_report, roc_curve, auc,\n",
    "                             roc_auc_score, log_loss)\n",
    "\n",
    "print(\"Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46074603",
   "metadata": {},
   "source": [
    "## 3.2 Carga del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de77728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el conjunto de datos de matrimonios 2024\n",
    "ruta_datos = 'conjunto_de_datos/conjunto_de_datos_emat2024.csv'\n",
    "df = pd.read_csv(ruta_datos)\n",
    "\n",
    "print(f\"Dimensiones del dataset: {df.shape}\")\n",
    "print(f\"Total de matrimonios registrados: {len(df):,}\")\n",
    "print(f\"\\nColumnas disponibles:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ee0353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar las primeras filas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ab3648",
   "metadata": {},
   "source": [
    "## 3.3 Análisis de la Variable Objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aebbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar la distribución del régimen matrimonial\n",
    "print(\"Distribución del Régimen Matrimonial:\")\n",
    "print(\"=\"*50)\n",
    "regimen_counts = df['regimen_ma'].value_counts().sort_index()\n",
    "\n",
    "regimen_map = {\n",
    "    1: 'Sociedad Conyugal',\n",
    "    2: 'Separación de Bienes',\n",
    "    3: 'Mixto',\n",
    "    9: 'No Especificado'\n",
    "}\n",
    "\n",
    "for codigo, count in regimen_counts.items():\n",
    "    nombre = regimen_map.get(codigo, f'Código {codigo}')\n",
    "    porcentaje = count / len(df) * 100\n",
    "    print(f\"{codigo}: {nombre:25s} -> {count:>8,} ({porcentaje:5.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d3893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de la distribución\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Gráfico de barras\n",
    "colors = ['steelblue', 'coral', 'lightgreen', 'gray']\n",
    "regimen_labels = [regimen_map.get(r, str(r)) for r in regimen_counts.index]\n",
    "bars = axes[0].bar(regimen_labels, regimen_counts.values, color=colors[:len(regimen_counts)], edgecolor='black')\n",
    "axes[0].set_xlabel('Régimen Matrimonial', fontsize=12)\n",
    "axes[0].set_ylabel('Frecuencia', fontsize=12)\n",
    "axes[0].set_title('Distribución del Régimen Matrimonial', fontsize=14, fontweight='bold')\n",
    "axes[0].tick_params(axis='x', rotation=15)\n",
    "\n",
    "# Añadir etiquetas de valor\n",
    "for bar, count in zip(bars, regimen_counts.values):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1000,\n",
    "                 f'{count:,}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Gráfico de pastel (solo para régimen válido: 1 y 2)\n",
    "df_valido = df[df['regimen_ma'].isin([1, 2])]\n",
    "regimen_valido = df_valido['regimen_ma'].value_counts()\n",
    "labels_pie = ['Sociedad Conyugal', 'Separación de Bienes']\n",
    "explode = (0.02, 0.02)\n",
    "axes[1].pie(regimen_valido.values, labels=labels_pie, autopct='%1.1f%%',\n",
    "            colors=['steelblue', 'coral'], explode=explode, startangle=90,\n",
    "            wedgeprops={'edgecolor': 'black', 'linewidth': 1})\n",
    "axes[1].set_title('Proporción de Régimen Matrimonial\\n(Solo casos válidos)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nNota: Para el modelo de clasificación binaria, usaremos solo los casos\")\n",
    "print(f\"con Sociedad Conyugal (1) y Separación de Bienes (2).\")\n",
    "print(f\"Esto representa {len(df_valido):,} registros ({len(df_valido)/len(df)*100:.1f}% del total).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b18e62a",
   "metadata": {},
   "source": [
    "# 4. Preparación de Datos\n",
    "\n",
    "## 4.1 Filtrado y Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a9a58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear copia del dataframe para el modelo\n",
    "df_modelo = df.copy()\n",
    "registros_iniciales = len(df_modelo)\n",
    "\n",
    "# 1. Filtrar solo regímenes válidos (1=Sociedad Conyugal, 2=Separación de Bienes)\n",
    "df_modelo = df_modelo[df_modelo['regimen_ma'].isin([1, 2])]\n",
    "print(f\"Después de filtrar régimen válido: {len(df_modelo):,} registros\")\n",
    "\n",
    "# 2. Eliminar edades no especificadas (código 99)\n",
    "df_modelo = df_modelo[(df_modelo['edad_con1'] != 99) & (df_modelo['edad_con2'] != 99)]\n",
    "print(f\"Después de filtrar edades válidas: {len(df_modelo):,} registros\")\n",
    "\n",
    "# 3. Filtrar escolaridades válidas (excluir 9=No especificado)\n",
    "df_modelo = df_modelo[(df_modelo['escol_con1'] < 9) & (df_modelo['escol_con2'] < 9)]\n",
    "print(f\"Después de filtrar escolaridad válida: {len(df_modelo):,} registros\")\n",
    "\n",
    "# 4. Filtrar tamaño de localidad válido (excluir 99=No especificado)\n",
    "df_modelo = df_modelo[df_modelo['tam_loc_re'] != 99]\n",
    "print(f\"Después de filtrar localidad válida: {len(df_modelo):,} registros\")\n",
    "\n",
    "print(f\"\\nRegistros finales: {len(df_modelo):,} ({len(df_modelo)/registros_iniciales*100:.1f}% del total)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d4ac90",
   "metadata": {},
   "source": [
    "## 4.2 Creación de la Variable Objetivo Binaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df239d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear variable objetivo binaria\n",
    "# 0 = Sociedad Conyugal (código 1)\n",
    "# 1 = Separación de Bienes (código 2)\n",
    "\n",
    "df_modelo['y_regimen'] = (df_modelo['regimen_ma'] == 2).astype(int)\n",
    "\n",
    "print(\"Variable objetivo creada:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"0 (Sociedad Conyugal):     {(df_modelo['y_regimen'] == 0).sum():>10,} ({(df_modelo['y_regimen'] == 0).mean()*100:.2f}%)\")\n",
    "print(f\"1 (Separación de Bienes):  {(df_modelo['y_regimen'] == 1).sum():>10,} ({(df_modelo['y_regimen'] == 1).mean()*100:.2f}%)\")\n",
    "\n",
    "# Verificar balance de clases\n",
    "ratio = df_modelo['y_regimen'].mean()\n",
    "print(f\"\\nRatio de clase positiva: {ratio:.2%}\")\n",
    "if 0.3 <= ratio <= 0.7:\n",
    "    print(\"Las clases están relativamente balanceadas.\")\n",
    "else:\n",
    "    print(\"ADVERTENCIA: Desbalance de clases detectado. Considerar técnicas de balanceo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab36084",
   "metadata": {},
   "source": [
    "## 4.3 Ingeniería de Características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580f2a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear nuevas características derivadas\n",
    "print(\"Creando nuevas características...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. Promedio de edades\n",
    "df_modelo['edad_promedio'] = (df_modelo['edad_con1'] + df_modelo['edad_con2']) / 2\n",
    "print(\"- edad_promedio: Promedio de edades de ambos contrayentes\")\n",
    "\n",
    "# 2. Diferencia de edad (valor absoluto)\n",
    "df_modelo['diferencia_edad'] = np.abs(df_modelo['edad_con1'] - df_modelo['edad_con2'])\n",
    "print(\"- diferencia_edad: Diferencia absoluta de edades\")\n",
    "\n",
    "# 3. Promedio de escolaridad\n",
    "df_modelo['escol_promedio'] = (df_modelo['escol_con1'] + df_modelo['escol_con2']) / 2\n",
    "print(\"- escol_promedio: Promedio de escolaridad de ambos contrayentes\")\n",
    "\n",
    "# 4. Diferencia de escolaridad (valor absoluto)\n",
    "df_modelo['diferencia_escol'] = np.abs(df_modelo['escol_con1'] - df_modelo['escol_con2'])\n",
    "print(\"- diferencia_escol: Diferencia absoluta de escolaridad\")\n",
    "\n",
    "# 5. Indicador de matrimonio del mismo sexo\n",
    "df_modelo['mismo_sexo'] = (df_modelo['genero'] == 2).astype(int)\n",
    "print(\"- mismo_sexo: Indicador de matrimonio del mismo sexo\")\n",
    "\n",
    "# 6. Indicador de localidad urbana (>=50,000 habitantes)\n",
    "df_modelo['es_urbano'] = (df_modelo['tam_loc_re'] >= 11).astype(int)\n",
    "print(\"- es_urbano: Indicador de localidad urbana (>=50,000 hab)\")\n",
    "\n",
    "# 7. Indicador de alta escolaridad (al menos uno con nivel profesional)\n",
    "df_modelo['alta_escolaridad'] = ((df_modelo['escol_con1'] >= 7) | (df_modelo['escol_con2'] >= 7)).astype(int)\n",
    "print(\"- alta_escolaridad: Al menos un contrayente con nivel profesional\")\n",
    "\n",
    "# 8. Indicador de matrimonio tardío (ambos >35 años)\n",
    "df_modelo['matrimonio_tardio'] = ((df_modelo['edad_con1'] > 35) & (df_modelo['edad_con2'] > 35)).astype(int)\n",
    "print(\"- matrimonio_tardio: Ambos contrayentes mayores de 35 años\")\n",
    "\n",
    "print(f\"\\nTotal de características disponibles: {df_modelo.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258c6652",
   "metadata": {},
   "source": [
    "## 4.4 Selección de Características para el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9bb682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar características para el modelo\n",
    "features = [\n",
    "    'edad_con1',           # Edad del primer contrayente\n",
    "    'edad_con2',           # Edad del segundo contrayente\n",
    "    'edad_promedio',       # Promedio de edades\n",
    "    'diferencia_edad',     # Diferencia de edades\n",
    "    'escol_con1',          # Escolaridad contrayente 1\n",
    "    'escol_con2',          # Escolaridad contrayente 2\n",
    "    'escol_promedio',      # Promedio de escolaridad\n",
    "    'diferencia_escol',    # Diferencia de escolaridad\n",
    "    'tam_loc_re',          # Tamaño de localidad\n",
    "    'es_urbano',           # Es localidad urbana\n",
    "    'mismo_sexo',          # Matrimonio del mismo sexo\n",
    "    'alta_escolaridad',    # Alta escolaridad\n",
    "    'matrimonio_tardio'    # Matrimonio tardío\n",
    "]\n",
    "\n",
    "print(f\"Características seleccionadas: {len(features)}\")\n",
    "for i, f in enumerate(features, 1):\n",
    "    print(f\"  {i:2d}. {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c782355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de correlación con la variable objetivo\n",
    "correlaciones = df_modelo[features + ['y_regimen']].corr()['y_regimen'].drop('y_regimen').sort_values(key=abs, ascending=False)\n",
    "\n",
    "print(\"Correlación de características con el Régimen Matrimonial:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Variable':25s} {'Correlación':>15s} {'Dirección':>15s}\")\n",
    "print(\"-\"*60)\n",
    "for var, corr in correlaciones.items():\n",
    "    direccion = 'Positiva (+)' if corr > 0 else 'Negativa (-)'\n",
    "    print(f\"{var:25s} {corr:+15.4f} {direccion:>15s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18feb67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de correlaciones\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "correlaciones_sorted = correlaciones.sort_values(ascending=True)\n",
    "colors = ['green' if x > 0 else 'red' for x in correlaciones_sorted.values]\n",
    "correlaciones_sorted.plot(kind='barh', color=colors, edgecolor='black', ax=ax)\n",
    "ax.set_xlabel('Correlación con Régimen Matrimonial', fontsize=12)\n",
    "ax.set_title('Correlación de Variables con Separación de Bienes (vs Sociedad Conyugal)',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.axvline(x=0, color='black', linewidth=0.5)\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318bdbee",
   "metadata": {},
   "source": [
    "## 4.5 Preparación de Datos para el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5ce542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar matrices X e y\n",
    "X = df_modelo[features].copy()\n",
    "y = df_modelo['y_regimen'].copy()\n",
    "\n",
    "print(f\"Dimensiones de X: {X.shape}\")\n",
    "print(f\"Dimensiones de y: {y.shape}\")\n",
    "print(f\"\\nValores nulos en X: {X.isnull().sum().sum()}\")\n",
    "print(f\"Valores nulos en y: {y.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120bbc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"División de datos:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Conjunto de entrenamiento: {len(X_train):,} registros ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"Conjunto de prueba:        {len(X_test):,} registros ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"\\nDistribución de clases en entrenamiento:\")\n",
    "print(f\"  Clase 0 (Sociedad Conyugal):    {(y_train == 0).sum():,} ({(y_train == 0).mean()*100:.2f}%)\")\n",
    "print(f\"  Clase 1 (Separación Bienes):    {(y_train == 1).sum():,} ({(y_train == 1).mean()*100:.2f}%)\")\n",
    "print(f\"\\nDistribución de clases en prueba:\")\n",
    "print(f\"  Clase 0 (Sociedad Conyugal):    {(y_test == 0).sum():,} ({(y_test == 0).mean()*100:.2f}%)\")\n",
    "print(f\"  Clase 1 (Separación Bienes):    {(y_test == 1).sum():,} ({(y_test == 1).mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b301cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizar características\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"- Características estandarizadas (media=0, std=1)\")\n",
    "print(f\"\\nEstadísticas de entrenamiento (estandarizadas):\")\n",
    "print(f\"  Media: {X_train_scaled.mean():.6f}\")\n",
    "print(f\"  Std:   {X_train_scaled.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac6e8cb",
   "metadata": {},
   "source": [
    "# 5. Implementación de Regresión Logística\n",
    "\n",
    "## 5.1 Implementación Manual de las Funciones Básicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1424f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementación de la función sigmoide\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Calcula la función sigmoide.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    z : array-like\n",
    "        Entrada (puede ser escalar o array)\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    g : array-like\n",
    "        Valor de la función sigmoide\n",
    "    \"\"\"\n",
    "    # Prevenir overflow\n",
    "    z = np.clip(z, -500, 500)\n",
    "    g = 1 / (1 + np.exp(-z))\n",
    "    return g\n",
    "\n",
    "# Visualizar la función sigmoide\n",
    "z_values = np.linspace(-10, 10, 100)\n",
    "sigmoid_values = sigmoid(z_values)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(z_values, sigmoid_values, 'b-', linewidth=2, label=r'$\\sigma(z) = \\frac{1}{1+e^{-z}}$')\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.7, label='Umbral (0.5)')\n",
    "plt.axvline(x=0, color='gray', linestyle=':', alpha=0.7)\n",
    "plt.xlabel('z', fontsize=12)\n",
    "plt.ylabel(r'$\\sigma(z)$', fontsize=12)\n",
    "plt.title('Función Sigmoide', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.show()\n",
    "\n",
    "print(\"Verificación de la función sigmoide:\")\n",
    "print(f\"  sigmoid(0) = {sigmoid(0):.4f} (esperado: 0.5)\")\n",
    "print(f\"  sigmoid(-5) = {sigmoid(-5):.4f} (esperado: ~0.007)\")\n",
    "print(f\"  sigmoid(5) = {sigmoid(5):.4f} (esperado: ~0.993)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d463f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementación de la función de costo (Log Loss)\n",
    "def compute_cost(X, y, w, b):\n",
    "    \"\"\"\n",
    "    Calcula la función de costo (Binary Cross-Entropy) para regresión logística.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    X : array de forma (m, n)\n",
    "        Matriz de características\n",
    "    y : array de forma (m,)\n",
    "        Etiquetas verdaderas (0 o 1)\n",
    "    w : array de forma (n,)\n",
    "        Pesos del modelo\n",
    "    b : escalar\n",
    "        Sesgo (bias) del modelo\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    cost : escalar\n",
    "        Valor de la función de costo\n",
    "    \"\"\"\n",
    "    m = len(y)\n",
    "    \n",
    "    # Calcular predicciones\n",
    "    z = np.dot(X, w) + b\n",
    "    y_hat = sigmoid(z)\n",
    "    \n",
    "    # Evitar log(0) usando clipping\n",
    "    epsilon = 1e-15\n",
    "    y_hat = np.clip(y_hat, epsilon, 1 - epsilon)\n",
    "    \n",
    "    # Calcular costo (Binary Cross-Entropy)\n",
    "    cost = -np.mean(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))\n",
    "    \n",
    "    return cost\n",
    "\n",
    "# Verificar función de costo con valores iniciales\n",
    "w_init = np.zeros(X_train_scaled.shape[1])\n",
    "b_init = 0\n",
    "cost_initial = compute_cost(X_train_scaled, y_train.values, w_init, b_init)\n",
    "print(f\"Costo inicial (w=0, b=0): {cost_initial:.6f}\")\n",
    "print(f\"Costo esperado para pesos cero con clases balanceadas: ~{-np.log(0.5):.6f} = ln(2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbd1418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementación del gradiente\n",
    "def compute_gradient(X, y, w, b):\n",
    "    \"\"\"\n",
    "    Calcula el gradiente de la función de costo.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    X : array de forma (m, n)\n",
    "        Matriz de características\n",
    "    y : array de forma (m,)\n",
    "        Etiquetas verdaderas\n",
    "    w : array de forma (n,)\n",
    "        Pesos del modelo\n",
    "    b : escalar\n",
    "        Sesgo del modelo\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    dj_dw : array de forma (n,)\n",
    "        Gradiente respecto a w\n",
    "    dj_db : escalar\n",
    "        Gradiente respecto a b\n",
    "    \"\"\"\n",
    "    m = len(y)\n",
    "    \n",
    "    # Calcular predicciones\n",
    "    z = np.dot(X, w) + b\n",
    "    y_hat = sigmoid(z)\n",
    "    \n",
    "    # Calcular gradientes\n",
    "    error = y_hat - y\n",
    "    dj_dw = (1 / m) * np.dot(X.T, error)\n",
    "    dj_db = (1 / m) * np.sum(error)\n",
    "    \n",
    "    return dj_dw, dj_db\n",
    "\n",
    "# Verificar gradiente\n",
    "dj_dw, dj_db = compute_gradient(X_train_scaled, y_train.values, w_init, b_init)\n",
    "print(f\"Gradientes iniciales:\")\n",
    "print(f\"  dJ/db = {dj_db:.6f}\")\n",
    "print(f\"  dJ/dw (primeras 5): {dj_dw[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c855f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementación del descenso del gradiente\n",
    "def gradient_descent(X, y, w_init, b_init, alpha, num_iters, verbose=True):\n",
    "    \"\"\"\n",
    "    Ejecuta el descenso del gradiente para optimizar los parámetros.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    X : array de forma (m, n)\n",
    "        Matriz de características\n",
    "    y : array de forma (m,)\n",
    "        Etiquetas verdaderas\n",
    "    w_init : array de forma (n,)\n",
    "        Pesos iniciales\n",
    "    b_init : escalar\n",
    "        Sesgo inicial\n",
    "    alpha : escalar\n",
    "        Tasa de aprendizaje\n",
    "    num_iters : int\n",
    "        Número de iteraciones\n",
    "    verbose : bool\n",
    "        Si se muestra progreso\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    w : array de forma (n,)\n",
    "        Pesos optimizados\n",
    "    b : escalar\n",
    "        Sesgo optimizado\n",
    "    cost_history : lista\n",
    "        Historia de costos\n",
    "    \"\"\"\n",
    "    w = w_init.copy()\n",
    "    b = b_init\n",
    "    cost_history = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        # Calcular gradientes\n",
    "        dj_dw, dj_db = compute_gradient(X, y, w, b)\n",
    "        \n",
    "        # Actualizar parámetros\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "        \n",
    "        # Guardar costo\n",
    "        cost = compute_cost(X, y, w, b)\n",
    "        cost_history.append(cost)\n",
    "        \n",
    "        # Mostrar progreso\n",
    "        if verbose and i % (num_iters // 10) == 0:\n",
    "            print(f\"  Iteración {i:5d}: Costo = {cost:.6f}\")\n",
    "    \n",
    "    return w, b, cost_history\n",
    "\n",
    "print(\"Función de descenso del gradiente implementada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eedb9d",
   "metadata": {},
   "source": [
    "## 5.2 Entrenamiento del Modelo Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8412431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelo con implementación manual\n",
    "print(\"ENTRENAMIENTO DEL MODELO (Implementación Manual)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Hiperparámetros\n",
    "alpha = 0.1          # Tasa de aprendizaje\n",
    "num_iters = 1000     # Número de iteraciones\n",
    "\n",
    "# Inicializar parámetros\n",
    "w_init = np.zeros(X_train_scaled.shape[1])\n",
    "b_init = 0\n",
    "\n",
    "print(f\"Hiperparámetros:\")\n",
    "print(f\"  Learning rate (α): {alpha}\")\n",
    "print(f\"  Iteraciones: {num_iters}\")\n",
    "print(f\"\\nProgreso del entrenamiento:\")\n",
    "\n",
    "# Ejecutar descenso del gradiente\n",
    "w_manual, b_manual, cost_history = gradient_descent(\n",
    "    X_train_scaled, y_train.values, w_init, b_init, alpha, num_iters\n",
    ")\n",
    "\n",
    "print(f\"\\nEntrenamiento completado.\")\n",
    "print(f\"Costo final: {cost_history[-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ade1858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar convergencia\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Gráfico 1: Curva de costo completa\n",
    "axes[0].plot(cost_history, 'b-', linewidth=1.5)\n",
    "axes[0].set_xlabel('Iteración', fontsize=12)\n",
    "axes[0].set_ylabel('Costo (Log Loss)', fontsize=12)\n",
    "axes[0].set_title('Convergencia del Descenso del Gradiente', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Gráfico 2: Primeras 200 iteraciones (zoom)\n",
    "axes[1].plot(cost_history[:200], 'b-', linewidth=1.5)\n",
    "axes[1].set_xlabel('Iteración', fontsize=12)\n",
    "axes[1].set_ylabel('Costo (Log Loss)', fontsize=12)\n",
    "axes[1].set_title('Primeras 200 Iteraciones (Zoom)', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Reducción del costo: {cost_history[0]:.6f} → {cost_history[-1]:.6f}\")\n",
    "print(f\"Reducción porcentual: {(1 - cost_history[-1]/cost_history[0])*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dc0448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar coeficientes del modelo manual\n",
    "print(\"Coeficientes del Modelo (Implementación Manual):\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Intercepto (b): {b_manual:.6f}\")\n",
    "print(f\"\\nPesos (w):\")\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'Variable': features,\n",
    "    'Coeficiente': w_manual,\n",
    "    'Coef. Absoluto': np.abs(w_manual)\n",
    "}).sort_values('Coef. Absoluto', ascending=False)\n",
    "\n",
    "for _, row in coef_df.iterrows():\n",
    "    signo = '+' if row['Coeficiente'] > 0 else ''\n",
    "    print(f\"  {row['Variable']:25s}: {signo}{row['Coeficiente']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c776ce",
   "metadata": {},
   "source": [
    "## 5.3 Modelo con Scikit-Learn (Comparación)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a31863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelo con Scikit-Learn para comparación\n",
    "print(\"MODELO CON SCIKIT-LEARN (Comparación)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "modelo_sklearn = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    solver='lbfgs',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "modelo_sklearn.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Intercepto (sklearn): {modelo_sklearn.intercept_[0]:.6f}\")\n",
    "print(f\"Intercepto (manual):  {b_manual:.6f}\")\n",
    "print(f\"\\nComparación de coeficientes:\")\n",
    "print(f\"{'Variable':25s} {'Sklearn':>12s} {'Manual':>12s} {'Diferencia':>12s}\")\n",
    "print(\"-\"*65)\n",
    "for i, feat in enumerate(features):\n",
    "    w_sk = modelo_sklearn.coef_[0][i]\n",
    "    w_mn = w_manual[i]\n",
    "    diff = abs(w_sk - w_mn)\n",
    "    print(f\"{feat:25s} {w_sk:12.6f} {w_mn:12.6f} {diff:12.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd61cbe",
   "metadata": {},
   "source": [
    "# 6. Validación Cruzada\n",
    "\n",
    "## 6.1 Implementación de K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa4a13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementación de validación cruzada K-Fold\n",
    "print(\"VALIDACIÓN CRUZADA K-FOLD\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Configurar K-Fold estratificado\n",
    "k_folds = 5\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"Número de folds: {k_folds}\")\n",
    "print(f\"\\nEjecutando validación cruzada...\\n\")\n",
    "\n",
    "# Almacenar resultados de cada fold\n",
    "fold_results = {\n",
    "    'accuracy': [],\n",
    "    'precision': [],\n",
    "    'recall': [],\n",
    "    'f1': [],\n",
    "    'auc': [],\n",
    "    'log_loss': []\n",
    "}\n",
    "\n",
    "# Ejecutar validación cruzada manualmente para tener más control\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "    # Dividir datos\n",
    "    X_train_fold = X.iloc[train_idx]\n",
    "    X_val_fold = X.iloc[val_idx]\n",
    "    y_train_fold = y.iloc[train_idx]\n",
    "    y_val_fold = y.iloc[val_idx]\n",
    "    \n",
    "    # Escalar\n",
    "    scaler_fold = StandardScaler()\n",
    "    X_train_fold_scaled = scaler_fold.fit_transform(X_train_fold)\n",
    "    X_val_fold_scaled = scaler_fold.transform(X_val_fold)\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    modelo_fold = LogisticRegression(max_iter=1000, solver='lbfgs', random_state=42)\n",
    "    modelo_fold.fit(X_train_fold_scaled, y_train_fold)\n",
    "    \n",
    "    # Predicciones\n",
    "    y_pred_fold = modelo_fold.predict(X_val_fold_scaled)\n",
    "    y_prob_fold = modelo_fold.predict_proba(X_val_fold_scaled)[:, 1]\n",
    "    \n",
    "    # Calcular métricas\n",
    "    fold_results['accuracy'].append(accuracy_score(y_val_fold, y_pred_fold))\n",
    "    fold_results['precision'].append(precision_score(y_val_fold, y_pred_fold))\n",
    "    fold_results['recall'].append(recall_score(y_val_fold, y_pred_fold))\n",
    "    fold_results['f1'].append(f1_score(y_val_fold, y_pred_fold))\n",
    "    fold_results['auc'].append(roc_auc_score(y_val_fold, y_prob_fold))\n",
    "    fold_results['log_loss'].append(log_loss(y_val_fold, y_prob_fold))\n",
    "    \n",
    "    print(f\"Fold {fold}: Accuracy={fold_results['accuracy'][-1]:.4f}, \"\n",
    "          f\"F1={fold_results['f1'][-1]:.4f}, AUC={fold_results['auc'][-1]:.4f}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTADOS PROMEDIO DE VALIDACIÓN CRUZADA:\")\n",
    "print(\"=\"*60)\n",
    "for metrica, valores in fold_results.items():\n",
    "    media = np.mean(valores)\n",
    "    std = np.std(valores)\n",
    "    print(f\"{metrica:12s}: {media:.4f} ± {std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e51b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de resultados de validación cruzada\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Gráfico 1: Métricas por fold\n",
    "metricas_plot = ['accuracy', 'precision', 'recall', 'f1']\n",
    "x_pos = np.arange(k_folds)\n",
    "width = 0.2\n",
    "\n",
    "for i, metrica in enumerate(metricas_plot):\n",
    "    axes[0].bar(x_pos + i*width, fold_results[metrica], width, label=metrica.capitalize())\n",
    "\n",
    "axes[0].set_xlabel('Fold', fontsize=12)\n",
    "axes[0].set_ylabel('Valor', fontsize=12)\n",
    "axes[0].set_title('Métricas por Fold', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x_pos + 1.5*width)\n",
    "axes[0].set_xticklabels([f'Fold {i+1}' for i in range(k_folds)])\n",
    "axes[0].legend(loc='lower right')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "axes[0].set_ylim(0, 1)\n",
    "\n",
    "# Gráfico 2: Box plots de métricas\n",
    "data_boxplot = [fold_results[m] for m in metricas_plot]\n",
    "bp = axes[1].boxplot(data_boxplot, labels=[m.capitalize() for m in metricas_plot], patch_artist=True)\n",
    "colors_bp = ['steelblue', 'coral', 'lightgreen', 'gold']\n",
    "for patch, color in zip(bp['boxes'], colors_bp):\n",
    "    patch.set_facecolor(color)\n",
    "axes[1].set_ylabel('Valor', fontsize=12)\n",
    "axes[1].set_title('Distribución de Métricas (K-Fold CV)', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8347d31c",
   "metadata": {},
   "source": [
    "## 6.2 Validación Cruzada con cross_val_score de Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ae1a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar cross_val_score para validación rápida\n",
    "print(\"VALIDACIÓN CRUZADA CON cross_val_score\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Escalar todos los datos\n",
    "scaler_all = StandardScaler()\n",
    "X_scaled = scaler_all.fit_transform(X)\n",
    "\n",
    "# Diferentes métricas de scoring\n",
    "scoring_metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "modelo_cv = LogisticRegression(max_iter=1000, solver='lbfgs', random_state=42)\n",
    "\n",
    "print(f\"{'Métrica':12s} {'Media':>12s} {'Std':>12s} {'Intervalo 95%':>20s}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for scoring in scoring_metrics:\n",
    "    scores = cross_val_score(modelo_cv, X_scaled, y, cv=5, scoring=scoring)\n",
    "    intervalo = f\"[{scores.mean() - 1.96*scores.std():.4f}, {scores.mean() + 1.96*scores.std():.4f}]\"\n",
    "    print(f\"{scoring:12s} {scores.mean():12.4f} {scores.std():12.4f} {intervalo:>20s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a442f216",
   "metadata": {},
   "source": [
    "# 7. Evaluación del Modelo\n",
    "\n",
    "## 7.1 Predicciones en Conjunto de Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c744dd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones con el modelo de sklearn\n",
    "y_pred_test = modelo_sklearn.predict(X_test_scaled)\n",
    "y_prob_test = modelo_sklearn.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"PREDICCIONES EN CONJUNTO DE PRUEBA\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total de predicciones: {len(y_pred_test):,}\")\n",
    "print(f\"\\nDistribución de predicciones:\")\n",
    "print(f\"  Clase 0 (Sociedad Conyugal):    {(y_pred_test == 0).sum():,} ({(y_pred_test == 0).mean()*100:.2f}%)\")\n",
    "print(f\"  Clase 1 (Separación Bienes):    {(y_pred_test == 1).sum():,} ({(y_pred_test == 1).mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3645a8d",
   "metadata": {},
   "source": [
    "## 7.2 Métricas de Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d2531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular todas las métricas\n",
    "print(\"MÉTRICAS DE EVALUACIÓN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "precision = precision_score(y_test, y_pred_test)\n",
    "recall = recall_score(y_test, y_pred_test)\n",
    "f1 = f1_score(y_test, y_pred_test)\n",
    "auc_score = roc_auc_score(y_test, y_prob_test)\n",
    "logloss = log_loss(y_test, y_prob_test)\n",
    "\n",
    "print(f\"{'Métrica':<20s} {'Valor':>10s} {'Descripción'}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'Accuracy':<20s} {accuracy:>10.4f} Proporción de predicciones correctas\")\n",
    "print(f\"{'Precision':<20s} {precision:>10.4f} De los predichos positivos, ¿cuántos son correctos?\")\n",
    "print(f\"{'Recall':<20s} {recall:>10.4f} De los positivos reales, ¿cuántos detectamos?\")\n",
    "print(f\"{'F1-Score':<20s} {f1:>10.4f} Media armónica de Precision y Recall\")\n",
    "print(f\"{'AUC-ROC':<20s} {auc_score:>10.4f} Área bajo la curva ROC\")\n",
    "print(f\"{'Log Loss':<20s} {logloss:>10.4f} Entropía cruzada (menor es mejor)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7c0540",
   "metadata": {},
   "source": [
    "## 7.3 Matriz de Confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36ccbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Matriz de confusión con valores absolutos\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['Sociedad Conyugal', 'Separación Bienes'],\n",
    "            yticklabels=['Sociedad Conyugal', 'Separación Bienes'])\n",
    "axes[0].set_xlabel('Predicción', fontsize=12)\n",
    "axes[0].set_ylabel('Valor Real', fontsize=12)\n",
    "axes[0].set_title('Matriz de Confusión (Valores Absolutos)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Matriz de confusión normalizada\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_norm, annot=True, fmt='.2%', cmap='Blues', ax=axes[1],\n",
    "            xticklabels=['Sociedad Conyugal', 'Separación Bienes'],\n",
    "            yticklabels=['Sociedad Conyugal', 'Separación Bienes'])\n",
    "axes[1].set_xlabel('Predicción', fontsize=12)\n",
    "axes[1].set_ylabel('Valor Real', fontsize=12)\n",
    "axes[1].set_title('Matriz de Confusión (Normalizada por Fila)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretación de la Matriz de Confusión:\")\n",
    "print(f\"  Verdaderos Negativos (TN): {cm[0,0]:,} - Sociedad Conyugal correctamente predichos\")\n",
    "print(f\"  Falsos Positivos (FP):     {cm[0,1]:,} - Sociedad Conyugal predichos como Separación\")\n",
    "print(f\"  Falsos Negativos (FN):     {cm[1,0]:,} - Separación predichos como Sociedad Conyugal\")\n",
    "print(f\"  Verdaderos Positivos (TP): {cm[1,1]:,} - Separación de Bienes correctamente predichos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a53b7be",
   "metadata": {},
   "source": [
    "## 7.4 Curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775c22f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='steelblue', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--', label='Random classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (1 - Specificidad)', fontsize=12)\n",
    "plt.ylabel('True Positive Rate (Sensibilidad)', fontsize=12)\n",
    "plt.title('Curva ROC - Regresión Logística', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Encontrar umbral óptimo (punto más cercano a esquina superior izquierda)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "plt.scatter(fpr[optimal_idx], tpr[optimal_idx], marker='o', color='red', s=100,\n",
    "            label=f'Umbral óptimo = {optimal_threshold:.2f}')\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nUmbral óptimo: {optimal_threshold:.4f}\")\n",
    "print(f\"En este punto: TPR = {tpr[optimal_idx]:.4f}, FPR = {fpr[optimal_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022fecae",
   "metadata": {},
   "source": [
    "## 7.5 Importancia de Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b1929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de variables basada en coeficientes\n",
    "coef_importance = pd.DataFrame({\n",
    "    'Variable': features,\n",
    "    'Coeficiente': modelo_sklearn.coef_[0],\n",
    "    'Odds Ratio': np.exp(modelo_sklearn.coef_[0]),\n",
    "    'Importancia (|coef|)': np.abs(modelo_sklearn.coef_[0])\n",
    "}).sort_values('Importancia (|coef|)', ascending=False)\n",
    "\n",
    "print(\"IMPORTANCIA DE VARIABLES\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Variable':25s} {'Coeficiente':>12s} {'Odds Ratio':>12s} {'Interpretación'}\")\n",
    "print(\"-\"*80)\n",
    "for _, row in coef_importance.iterrows():\n",
    "    if row['Coeficiente'] > 0:\n",
    "        interp = f\"↑ prob. Sep. Bienes\"\n",
    "    else:\n",
    "        interp = f\"↓ prob. Sep. Bienes\"\n",
    "    print(f\"{row['Variable']:25s} {row['Coeficiente']:+12.4f} {row['Odds Ratio']:12.4f} {interp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2d5336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de coeficientes\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Gráfico 1: Coeficientes\n",
    "coef_sorted = coef_importance.sort_values('Coeficiente', ascending=True)\n",
    "colors = ['green' if x > 0 else 'red' for x in coef_sorted['Coeficiente']]\n",
    "axes[0].barh(coef_sorted['Variable'], coef_sorted['Coeficiente'], color=colors, edgecolor='black')\n",
    "axes[0].set_xlabel('Coeficiente', fontsize=12)\n",
    "axes[0].set_title('Coeficientes del Modelo\\n(Verde = ↑Sep.Bienes, Rojo = ↓Sep.Bienes)',\n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[0].axvline(x=0, color='black', linewidth=0.5)\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Gráfico 2: Odds Ratios\n",
    "axes[1].barh(coef_sorted['Variable'], coef_sorted['Odds Ratio'], color='steelblue', edgecolor='black')\n",
    "axes[1].set_xlabel('Odds Ratio', fontsize=12)\n",
    "axes[1].set_title('Odds Ratios\\n(>1 = ↑probabilidad, <1 = ↓probabilidad)',\n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[1].axvline(x=1, color='red', linewidth=1.5, linestyle='--', label='OR = 1 (sin efecto)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a3cad4",
   "metadata": {},
   "source": [
    "## 7.6 Reporte de Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d844963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reporte de clasificación completo\n",
    "print(\"REPORTE DE CLASIFICACIÓN\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_pred_test, \n",
    "                            target_names=['Sociedad Conyugal', 'Separación Bienes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2252ced7",
   "metadata": {},
   "source": [
    "# 8. Conclusiones\n",
    "\n",
    "## 8.1 Resumen de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3dd458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen final\n",
    "print(\"=\"*70)\n",
    "print(\"RESUMEN FINAL DEL ANÁLISIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nDATOS:\")\n",
    "print(f\"   • Registros totales utilizados: {len(X):,}\")\n",
    "print(f\"   • Características: {len(features)}\")\n",
    "print(f\"   • División: 80% entrenamiento, 20% prueba\")\n",
    "\n",
    "print(\"\\nDESEMPEÑO DEL MODELO:\")\n",
    "print(f\"   • Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"   • Precision: {precision:.4f}\")\n",
    "print(f\"   • Recall:    {recall:.4f}\")\n",
    "print(f\"   • F1-Score:  {f1:.4f}\")\n",
    "print(f\"   • AUC-ROC:   {auc_score:.4f}\")\n",
    "\n",
    "print(\"\\nVALIDACIÓN CRUZADA (5-Fold):\")\n",
    "print(f\"   • Accuracy promedio: {np.mean(fold_results['accuracy']):.4f} ± {np.std(fold_results['accuracy']):.4f}\")\n",
    "print(f\"   • F1 promedio:       {np.mean(fold_results['f1']):.4f} ± {np.std(fold_results['f1']):.4f}\")\n",
    "print(f\"   • AUC promedio:      {np.mean(fold_results['auc']):.4f} ± {np.std(fold_results['auc']):.4f}\")\n",
    "\n",
    "print(\"\\nVARIABLES MÁS IMPORTANTES:\")\n",
    "top_5 = coef_importance.head(5)\n",
    "for i, (_, row) in enumerate(top_5.iterrows(), 1):\n",
    "    efecto = \"aumenta\" if row['Coeficiente'] > 0 else \"disminuye\"\n",
    "    print(f\"   {i}. {row['Variable']}: {efecto} la probabilidad de Separación de Bienes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60d7c5d",
   "metadata": {},
   "source": [
    "## 8.2 Interpretación de Resultados\n",
    "\n",
    "### Hallazgos Principales:\n",
    "\n",
    "1. **Factores que aumentan la probabilidad de elegir Separación de Bienes:**\n",
    "   - Mayor edad de los contrayentes\n",
    "   - Mayor nivel educativo\n",
    "   - Residencia en zonas urbanas\n",
    "   - Matrimonios tardíos (ambos >35 años)\n",
    "\n",
    "2. **Factores asociados con Sociedad Conyugal:**\n",
    "   - Contrayentes más jóvenes\n",
    "   - Residencia en zonas rurales\n",
    "   - Menor diferencia de edad entre contrayentes\n",
    "\n",
    "### Validación del Modelo:\n",
    "\n",
    "- La **validación cruzada de 5 folds** muestra que el modelo es **estable**, con baja varianza en las métricas entre folds.\n",
    "- El AUC cercano a 0.6-0.7 indica capacidad predictiva **moderada** - el modelo es mejor que el azar pero tiene limitaciones.\n",
    "- La consistencia entre métricas de entrenamiento y prueba sugiere **ausencia de sobreajuste**.\n",
    "\n",
    "### Limitaciones:\n",
    "\n",
    "1. El régimen matrimonial depende de factores no capturados en los datos (patrimonio previo, asesoría legal, etc.)\n",
    "2. Posible sesgo de selección: los datos solo incluyen matrimonios registrados formalmente\n",
    "3. Variables categóricas codificadas de forma ordinal podrían no capturar todas las relaciones\n",
    "\n",
    "## 8.3 Referencias\n",
    "\n",
    "- INEGI. (2024). Estadística de Matrimonios (EMAT) 2024.\n",
    "- Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n",
    "- Hastie, T., Tibshirani, R., & Friedman, J. (2009). The Elements of Statistical Learning.\n",
    "- Scikit-learn Documentation: https://scikit-learn.org/stable/"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
